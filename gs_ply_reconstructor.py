"""
3DGS PLY Reconstructor - DEBUG VERSION
=======================================
Comprehensive diagnostics to identify training issues
"""

import numpy as np
from pathlib import Path
from typing import Optional
from plyfile import PlyData, PlyElement

# â”€â”€ constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

C0  = 0.28209479177387814   # SH DC constant
EPS = 1e-7

# â”€â”€ parameter slices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

COORD_SLICE   = slice(0,  3)
COLOR_SLICE   = slice(3,  6)
OPACITY_SLICE = slice(6,  7)
SCALE_SLICE   = slice(7,  10)
QUAT_SLICE    = slice(10, 14)


# â”€â”€ activation inversions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def logit(p: np.ndarray) -> np.ndarray:
    """Inverse of sigmoid."""
    p = np.clip(p.astype(np.float64), EPS, 1.0 - EPS)
    return np.log(p / (1.0 - p)).astype(np.float32)


def safe_log(s: np.ndarray) -> np.ndarray:
    """Inverse of exp."""
    return np.log(np.maximum(s.astype(np.float64), EPS)).astype(np.float32)


# â”€â”€ colour conversion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def rgb_to_f_dc(rgb: np.ndarray) -> np.ndarray:
    """RGB â†’ SH DC coefficients."""
    rgb = np.clip(rgb.astype(np.float32), 0.0, 1.0)
    return ((rgb - 0.5) / C0).astype(np.float32)


# â”€â”€ quaternion normalisation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def normalize_quaternion(quat: np.ndarray) -> np.ndarray:
    norm = np.linalg.norm(quat, axis=1, keepdims=True)
    norm = np.where(norm > EPS, norm, 1.0)
    return (quat / norm).astype(np.float32)


# â”€â”€ PLY vertex struct â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_vertex_struct(
    coord:      np.ndarray,
    f_dc:       np.ndarray,
    ply_opacity: np.ndarray,
    ply_scales:  np.ndarray,
    quat:       np.ndarray,
    max_sh_degree: int = 3,
    normals: Optional[np.ndarray] = None,
) -> np.ndarray:
    N = coord.shape[0]

    quat        = normalize_quaternion(quat.reshape(N, 4))
    normals     = normals.astype(np.float32) if normals is not None \
                  else np.zeros((N, 3), dtype=np.float32)
    ply_opacity = ply_opacity.reshape(N).astype(np.float32)
    ply_scales  = ply_scales.reshape(N, 3).astype(np.float32)
    f_dc        = f_dc.reshape(N, 3).astype(np.float32)

    num_f_rest = 3 * ((max_sh_degree + 1) ** 2 - 1)

    dtype_list = (
        [("x","f4"), ("y","f4"), ("z","f4")]
      + [("nx","f4"), ("ny","f4"), ("nz","f4")]
      + [(f"f_dc_{i}",   "f4") for i in range(3)]
      + [(f"f_rest_{i}", "f4") for i in range(num_f_rest)]
      + [("opacity", "f4")]
      + [(f"scale_{i}", "f4") for i in range(3)]
      + [(f"rot_{i}",   "f4") for i in range(4)]
    )

    vert = np.empty(N, dtype=dtype_list)

    vert["x"], vert["y"], vert["z"]    = coord[:,0],   coord[:,1],   coord[:,2]
    vert["nx"], vert["ny"], vert["nz"] = normals[:,0], normals[:,1], normals[:,2]

    for i in range(3):
        vert[f"f_dc_{i}"] = f_dc[:, i]

    for i in range(num_f_rest):
        vert[f"f_rest_{i}"] = 0.0

    vert["opacity"] = ply_opacity

    for i in range(3):
        vert[f"scale_{i}"] = ply_scales[:, i]

    for i in range(4):
        vert[f"rot_{i}"] = quat[:, i]

    return vert


# â”€â”€ ğŸ” COMPREHENSIVE DIAGNOSTICS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def diagnose_scene(coord, rgb, opacity, scale, quat, ply_scales, ply_opacity):
    """Print comprehensive diagnostic information."""
    
    print(f"\n{'='*70}")
    print(f"ğŸ” COMPREHENSIVE SCENE DIAGNOSTICS")
    print(f"{'='*70}")
    
    # â”€â”€ POSITION ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ“ POSITION ANALYSIS:")
    print(f"  Range:     [{coord.min():.3f}, {coord.max():.3f}]m")
    print(f"  Mean:      [{coord.mean(axis=0)}]")
    print(f"  Std:       [{coord.std(axis=0)}]")
    print(f"  Spread:    {coord.max() - coord.min():.3f}m")
    
    # Expected for canonical sphere (10m radius):
    expected_range = "Â±9m"
    if coord.min() > -8.0 or coord.max() < 8.0:
        print(f"  âš ï¸  COMPRESSED! Expected {expected_range}, got [{coord.min():.1f}, {coord.max():.1f}]")
        print(f"  â†’ Model output range is smaller than target")
        print(f"  â†’ Position loss will plateau at ~5.0")
    else:
        print(f"  âœ“  Good range (matches canonical sphere)")
    
    # â”€â”€ COLOR ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ¨ COLOR ANALYSIS:")
    print(f"  Range:     [{rgb.min():.3f}, {rgb.max():.3f}]")
    print(f"  Mean:      {rgb.mean():.3f}")
    print(f"  Std:       {rgb.std():.3f}")
    
    rgb_spread = rgb.max() - rgb.min()
    print(f"  Spread:    {rgb_spread:.3f}")
    
    if rgb.std() < 0.1:
        print(f"  âš ï¸  ALL GRAY! (std < 0.1)")
        print(f"  â†’ Colors clustered around {rgb.mean():.2f}")
        print(f"  â†’ Model not learning per-scene colors")
        print(f"  â†’ Color loss stuck at ~12.0")
    elif rgb.std() < 0.15:
        print(f"  âš ï¸  Limited color variation (std < 0.15)")
    else:
        print(f"  âœ“  Good color variation")
    
    # Color histogram
    bins = [0, 0.3, 0.4, 0.5, 0.6, 0.7, 1.0]
    hist, _ = np.histogram(rgb.flatten(), bins=bins)
    print(f"  Distribution:")
    print(f"    [0.0-0.3]: {hist[0]/len(rgb.flatten())*100:.1f}%")
    print(f"    [0.3-0.4]: {hist[1]/len(rgb.flatten())*100:.1f}%")
    print(f"    [0.4-0.5]: {hist[2]/len(rgb.flatten())*100:.1f}%  â† dark gray")
    print(f"    [0.5-0.6]: {hist[3]/len(rgb.flatten())*100:.1f}%  â† mid gray")
    print(f"    [0.6-0.7]: {hist[4]/len(rgb.flatten())*100:.1f}%  â† light gray")
    print(f"    [0.7-1.0]: {hist[5]/len(rgb.flatten())*100:.1f}%")
    
    # â”€â”€ OPACITY ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ‘ï¸  OPACITY ANALYSIS:")
    print(f"  Model output:  [{opacity.min():.3f}, {opacity.max():.3f}]")
    
    # Check for values outside [0, 1]
    num_clamped = np.sum(opacity > 1.0)
    if num_clamped > 0:
        print(f"  âš ï¸  {num_clamped} values > 1.0 (will be clamped)")
    
    # Rendered opacity after sigmoid
    opacity_rendered = 1.0 / (1.0 + np.exp(-ply_opacity.astype(np.float64)))
    print(f"  After sigmoid: [{opacity_rendered.min():.3f}, {opacity_rendered.max():.3f}]")
    
    avg_opacity = opacity_rendered.mean()
    print(f"  Mean opacity:  {avg_opacity:.3f}")
    
    if avg_opacity < 0.5:
        print(f"  âš ï¸  LOW! (< 0.5) â†’ Splats too transparent â†’ cloudy appearance")
    elif avg_opacity < 0.8:
        print(f"  âš ï¸  Medium (0.5-0.8) â†’ Partially transparent")
    else:
        print(f"  âœ“  High (> 0.8) â†’ Splats are opaque")
    
    # â”€â”€ SCALE ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ“ SCALE ANALYSIS:")
    print(f"  Model output:  [{scale.min():.4f}, {scale.max():.4f}]m")
    
    # Check for negative or zero scales
    num_negative = np.sum(scale <= 0)
    if num_negative > 0:
        print(f"  âš ï¸  {num_negative} NEGATIVE/ZERO scales! (impossible for post-exp)")
        print(f"  â†’ Model initialization problem or activation missing")
    
    # After log (for PLY)
    scale_rendered = np.exp(ply_scales.astype(np.float64))
    print(f"  After exp:     [{scale_rendered.min():.4f}, {scale_rendered.max():.4f}]m")
    
    avg_scale = scale_rendered.mean()
    print(f"  Mean scale:    {avg_scale:.3f}m = {avg_scale*100:.1f}cm")
    
    # Invisible splats (too small)
    num_tiny = np.sum(ply_scales <= -10)
    if num_tiny > 0:
        print(f"  âš ï¸  {num_tiny} invisible splats (scale â‰¤ -10 in PLY)")
    
    # Scale interpretation
    if avg_scale > 0.5:
        print(f"  âš ï¸  LARGE! (> 0.5m = 50cm) â†’ Splats blooming into each other")
        print(f"  â†’ Gray cloud appearance")
        print(f"  â†’ Scale loss should decrease (currently stuck?)")
    elif avg_scale > 0.2:
        print(f"  âš ï¸  Medium (20-50cm) â†’ Overlapping splats")
    else:
        print(f"  âœ“  Small (< 20cm) â†’ Appropriate for indoor scenes")
    
    # Scale distribution
    print(f"  Distribution:")
    print(f"    < 5cm:   {np.sum(scale_rendered < 0.05)/len(scale_rendered.flatten())*100:.1f}%")
    print(f"    5-10cm:  {np.sum((scale_rendered >= 0.05) & (scale_rendered < 0.10))/len(scale_rendered.flatten())*100:.1f}%")
    print(f"    10-20cm: {np.sum((scale_rendered >= 0.10) & (scale_rendered < 0.20))/len(scale_rendered.flatten())*100:.1f}%")
    print(f"    > 20cm:  {np.sum(scale_rendered >= 0.20)/len(scale_rendered.flatten())*100:.1f}%")
    
    # â”€â”€ ROTATION ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\nğŸ”„ ROTATION ANALYSIS:")
    quat_norm = np.linalg.norm(quat, axis=1)
    print(f"  Quaternion norm: [{quat_norm.min():.3f}, {quat_norm.max():.3f}]")
    
    if np.abs(quat_norm.mean() - 1.0) > 0.1:
        print(f"  âš ï¸  Not normalized! (mean norm = {quat_norm.mean():.3f})")
    else:
        print(f"  âœ“  Properly normalized")
    
    print(f"{'='*70}\n")


# â”€â”€ single-scene reconstruction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def reconstruct_single_scene(
    prediction:    np.ndarray,
    output_path:   Path,
    max_sh_degree: int = 3,
    verbose:       bool = True,
    color_mode:    str = "1",
) -> Optional[str]:
    """Convert model output to 3DGS PLY with comprehensive diagnostics."""
    try:
        N = prediction.shape[0]

        coord   = prediction[:, COORD_SLICE  ].astype(np.float32)
        rgb     = prediction[:, COLOR_SLICE  ].astype(np.float32)
        opacity = prediction[:, OPACITY_SLICE].astype(np.float32)
        scale   = prediction[:, SCALE_SLICE  ].astype(np.float32)
        quat    = prediction[:, QUAT_SLICE   ].astype(np.float32)

        # Invert activations
        ply_opacity = logit(opacity)
        ply_scales  = safe_log(scale)

        # ğŸ” RUN DIAGNOSTICS
        if verbose:
            diagnose_scene(coord, rgb, opacity, scale, quat, ply_scales, ply_opacity)

        f_dc = rgb_to_f_dc(rgb)

        vertex = build_vertex_struct(
            coord=coord,
            f_dc=f_dc,
            ply_opacity=ply_opacity,
            ply_scales=ply_scales,
            quat=quat,
            max_sh_degree=max_sh_degree,
        )

        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        PlyData([PlyElement.describe(vertex, "vertex")], text=False).write(str(output_path))

        print(f"âœ“ Saved: {output_path}")
        return str(output_path)

    except Exception as e:
        print(f"âš ï¸  Error: {e}")
        import traceback; traceback.print_exc()
        return None


# â”€â”€ batch reconstruction â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def save_reconstructed_gaussians(
    predictions:   np.ndarray,
    output_dir:    Path,
    epoch:         int,
    num_scenes:    int = 5,
    max_sh_degree: int = 3,
    color_mode:    str = "1",
    prefix:        str = "scene",
) -> dict:
    """Save reconstructed scenes with diagnostics."""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    n_save = min(num_scenes, predictions.shape[0])
    saved  = {}

    print(f"\n{'='*70}")
    print(f"3DGS RECONSTRUCTION - Epoch {epoch}")
    print(f"{'='*70}")

    for i in range(n_save):
        print(f"\nğŸ“¦ Scene {i}/{n_save-1}:")
        out_path = output_dir / f"{prefix}_{i:03d}_epoch_{epoch:03d}.ply"
        
        path = reconstruct_single_scene(
            prediction=predictions[i],
            output_path=out_path,
            max_sh_degree=max_sh_degree,
            verbose=True,
        )
        
        if path:
            saved[f"scene_{i:03d}"] = path

    print(f"\n{'='*70}")
    print(f"âœ“ Saved {len(saved)}/{n_save} scenes")
    print(f"  Location: {output_dir}")
    print(f"  View at: https://supersplat.at")
    print(f"{'='*70}\n")

    return saved